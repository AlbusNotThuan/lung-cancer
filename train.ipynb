{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1da0b6",
   "metadata": {},
   "source": [
    "## ðŸš€ Google Colab Setup\n",
    "\n",
    "**Run these commands in Colab before running the notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ab5502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/abc/Documents/auto-labeling\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (2.3.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: xgboost>=1.5.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (3.1.3)\n",
      "Requirement already satisfied: lightgbm>=3.3.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (4.6.0)\n",
      "Requirement already satisfied: imbalanced-learn>=0.9.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.4.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: joblib>=1.1.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (3.10.6)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from auto-labeling==0.1.0) (1.16.3)\n",
      "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from imbalanced-learn>=0.9.0->auto-labeling==0.1.0) (0.1.5)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from imbalanced-learn>=0.9.0->auto-labeling==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from matplotlib>=3.4.0->auto-labeling==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from pandas>=1.3.0->auto-labeling==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from pandas>=1.3.0->auto-labeling==0.1.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abc\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->auto-labeling==0.1.0) (1.17.0)\n",
      "Installing collected packages: auto-labeling\n",
      "  Attempting uninstall: auto-labeling\n",
      "    Found existing installation: auto-labeling 0.1.0\n",
      "    Uninstalling auto-labeling-0.1.0:\n",
      "      Successfully uninstalled auto-labeling-0.1.0\n",
      "  Running setup.py develop for auto-labeling\n",
      "Successfully installed auto-labeling-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Legacy editable install of auto-labeling==0.1.0 from file:///C:/Users/abc/Documents/auto-labeling (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/projects/auto-labeling\n",
    "\n",
    "# Install package in development mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c92b3e",
   "metadata": {},
   "source": [
    "# Modular Training Pipeline\n",
    "\n",
    "This notebook trains multiple ML models with configurable imbalance handling methods in parallel.\n",
    "\n",
    "**Features:**\n",
    "- 11 ML models supported\n",
    "- 6 imbalance handling methods\n",
    "- Parallel training (n_workers configurable)\n",
    "- Binary and multiclass classification\n",
    "- Automatic result tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f459188",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c86e2481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules from local directories\n",
    "from datasets import DatasetFactory\n",
    "from modules.imbalance_handler import ImbalanceHandler\n",
    "from modules.models import ModelFactory\n",
    "from modules.trainer import Trainer\n",
    "from modules.evaluator import Evaluator\n",
    "from modules.visualizer import Visualizer\n",
    "\n",
    "print(\"âœ… All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4eae63",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for Result Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03da7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_run_folder():\n",
    "    \"\"\"Create timestamped run folder\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_folder = f\"results/run_{timestamp}\"\n",
    "    os.makedirs(run_folder, exist_ok=True)\n",
    "    os.makedirs(f\"{run_folder}/plots\", exist_ok=True)\n",
    "    return run_folder\n",
    "\n",
    "def save_summary(run_folder, config, metrics_df, dataset_info):\n",
    "    \"\"\"Save quick summary JSON\"\"\"\n",
    "    best_idx = metrics_df['auc'].idxmax()\n",
    "    \n",
    "    summary = {\n",
    "        \"experiment\": config['experiment'],\n",
    "        \"dataset\": dataset_info,\n",
    "        \"models\": config['models']['active'],\n",
    "        \"imbalance_methods\": config['imbalance']['methods'],\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"best_result\": {\n",
    "            \"job\": f\"{metrics_df.loc[best_idx, 'model']}_{metrics_df.loc[best_idx, 'imbalance_method']}\",\n",
    "            \"model\": metrics_df.loc[best_idx, 'model'],\n",
    "            \"imbalance_method\": metrics_df.loc[best_idx, 'imbalance_method'],\n",
    "            \"auc\": float(metrics_df.loc[best_idx, 'auc']),\n",
    "            \"accuracy\": float(metrics_df.loc[best_idx, 'accuracy'])\n",
    "        },\n",
    "        \"config\": config\n",
    "    }\n",
    "    \n",
    "    with open(f\"{run_folder}/summary.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "def save_metrics(run_folder, metrics_df):\n",
    "    \"\"\"Save detailed metrics CSV\"\"\"\n",
    "    metrics_df.to_csv(f\"{run_folder}/metrics.csv\", index=False)\n",
    "\n",
    "def save_training_log(run_folder, log_messages):\n",
    "    \"\"\"Save raw training logs\"\"\"\n",
    "    with open(f\"{run_folder}/training.log\", 'w') as f:\n",
    "        f.write('\\n'.join(log_messages))\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492b56a",
   "metadata": {},
   "source": [
    "## 3. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1b7d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Configuration loaded:\n",
      "  Experiment: baseline_all_models\n",
      "  Dataset: lung_cancer\n",
      "  Models: 11\n",
      "  Imbalance methods: 6\n",
      "  Parallel workers: 4\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"ðŸ“‹ Configuration loaded:\")\n",
    "print(f\"  Experiment: {config['experiment']['name']}\")\n",
    "print(f\"  Dataset: {config['dataset']['name']}\")\n",
    "print(f\"  Models: {len(config['models']['active'])}\")\n",
    "print(f\"  Imbalance methods: {len(config['imbalance']['methods'])}\")\n",
    "print(f\"  Parallel workers: {config['training']['n_workers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16b381",
   "metadata": {},
   "source": [
    "## 4. Create Run Folder and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e5a1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Results will be saved to: results/run_20260208_223713\n",
      "\n",
      "ðŸ“Š Dataset: lung_cancer\n",
      "  Description: Lung cancer 2-year survival prediction from index_age\n",
      "  Task: binary\n",
      "  Train: (19000, 52)\n",
      "  Test: (11444, 52)\n",
      "  Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Create run folder\n",
    "run_folder = create_run_folder()\n",
    "log = []\n",
    "\n",
    "# Optional: create models folder if saving models\n",
    "if config['output']['save_models']:\n",
    "    os.makedirs(f\"{run_folder}/models\", exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“ Results will be saved to: {run_folder}\")\n",
    "\n",
    "# Load dataset using DatasetFactory\n",
    "dataset_name = config['dataset']['name']\n",
    "dataset, X_train, y_train, X_test, y_test, dataset_info = \\\n",
    "    DatasetFactory.load_dataset(dataset_name)\n",
    "\n",
    "log.append(f\"Loaded dataset: {dataset_info['name']}\")\n",
    "log.append(f\"Task type: {dataset_info['task_type']}\")\n",
    "log.append(f\"Training samples: {len(X_train)}\")\n",
    "log.append(f\"Test samples: {len(X_test)}\")\n",
    "log.append(f\"Features: {X_train.shape[1]}\")\n",
    "log.append(f\"Classes: {np.unique(y_train)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset: {dataset_info['name']}\")\n",
    "print(f\"  Description: {dataset_info['description']}\")\n",
    "print(f\"  Task: {dataset_info['task_type']}\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")\n",
    "print(f\"  Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf9151",
   "metadata": {},
   "source": [
    "## 5. Define Training Job Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ba57623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training job function defined\n"
     ]
    }
   ],
   "source": [
    "def train_single_job(model_name, imbalance_method, X_train, y_train, X_test, y_test, config, dataset_info):\n",
    "    \"\"\"Train a single model with given imbalance method\"\"\"\n",
    "    job_log = []\n",
    "    job_name = f\"{model_name}_{imbalance_method}\"\n",
    "    \n",
    "    # Apply imbalance handling\n",
    "    imbalance_handler = ImbalanceHandler(\n",
    "        method=imbalance_method,\n",
    "        **config['imbalance']['params']\n",
    "    )\n",
    "\n",
    "    X_train_balanced, y_train_balanced = imbalance_handler.apply(\n",
    "        X_train.copy(), y_train.copy(), task_type=dataset_info['task_type']\n",
    "    )\n",
    "\n",
    "    # DEBUG: Print status after applying imbalance handling\n",
    "    print(f\"Class distribution before: {np.bincount(y_train)}\")\n",
    "    print(f\"After applying imbalance method; Class distribution: {np.bincount(y_train_balanced)}\")\n",
    "    print(f\"Samples before/after: {len(X_train)}/{len(X_train_balanced)}\\n\")\n",
    "\n",
    "    job_log.append(f\"Samples: {len(X_train)} -> {len(X_train_balanced)}\")\n",
    "    \n",
    "    # Create model\n",
    "    params = config['models'].get('params', {}).get(model_name, {})\n",
    "    model = ModelFactory.create_model(model_name, params)\n",
    "    \n",
    "    # Add scaler if needed\n",
    "    scaler = StandardScaler() if ModelFactory.requires_scaling(model_name) else None\n",
    "    \n",
    "    # Train\n",
    "    trainer = Trainer(model, model_name, scaler)\n",
    "    trainer.train(X_train_balanced, y_train_balanced)\n",
    "    job_log.append(f\"Training time: {trainer.train_time:.2f}s\")\n",
    "    \n",
    "    # Predict\n",
    "    if dataset_info['task_type'] == \"binary\":\n",
    "        y_pred_proba = trainer.predict_proba(X_test)\n",
    "    else:\n",
    "        # For multiclass, get full probability matrix\n",
    "        if scaler:\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_config = config['evaluation']\n",
    "    evaluator = Evaluator(\n",
    "        thresholds=eval_config['thresholds'],\n",
    "        task_type=dataset_info['task_type'],\n",
    "        average=eval_config.get('multiclass', {}).get('average', 'macro')\n",
    "    )\n",
    "    metrics = evaluator.evaluate_model(y_test, y_pred_proba, model_name, imbalance_method, trainer.train_time)\n",
    "    \n",
    "    return {\n",
    "        'job_name': job_name,\n",
    "        'model_name': model_name,\n",
    "        'imbalance_method': imbalance_method,\n",
    "        'metrics': metrics,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'trainer': trainer,\n",
    "        'log': job_log\n",
    "    }\n",
    "\n",
    "print(\"âœ… Training job function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8482b8",
   "metadata": {},
   "source": [
    "## 6. Generate Training Jobs and Train in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54ea8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run a single job for testing\n",
    "# result = train_single_job(\n",
    "#     model_name=config['models']['active'][0],\n",
    "#     imbalance_method=config['imbalance']['methods'][0],\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     config=config,\n",
    "#     dataset_info=dataset_info\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c63b86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting parallel training...\n",
      "  Total jobs: 66\n",
      "  Workers: 4\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  9.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "âœ… All training jobs completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  66 out of  66 | elapsed: 11.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Generate all training jobs (model x imbalance_method combinations)\n",
    "training_jobs = []\n",
    "for model_name in config['models']['active']:\n",
    "    for imbalance_method in config['imbalance']['methods']:\n",
    "        training_jobs.append((model_name, imbalance_method))\n",
    "\n",
    "print(f\"\\nðŸš€ Starting parallel training...\")\n",
    "print(f\"  Total jobs: {len(training_jobs)}\")\n",
    "print(f\"  Workers: {config['training']['n_workers']}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "\n",
    "log.append(f\"\\nTotal training jobs: {len(training_jobs)}\")\n",
    "log.append(f\"Parallel workers: {config['training']['n_workers']}\")\n",
    "\n",
    "# Train all jobs in parallel\n",
    "results = Parallel(n_jobs=config['training']['n_workers'], verbose=10)(\n",
    "    delayed(train_single_job)(\n",
    "        model_name, imbalance_method, \n",
    "        X_train, y_train, X_test, y_test, \n",
    "        config, dataset_info\n",
    "    )\n",
    "    for model_name, imbalance_method in training_jobs\n",
    ")\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nâœ… All training jobs completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2889d",
   "metadata": {},
   "source": [
    "## 7. Collect Results and Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30d44a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Results collected:\n",
      "  Total models trained: 66\n",
      "  Metrics computed: 66\n"
     ]
    }
   ],
   "source": [
    "# Collect results\n",
    "results_dict = {}  # For visualization: {job_name: y_pred_proba}\n",
    "all_metrics = []\n",
    "\n",
    "for result in results:\n",
    "    job_name = result['job_name']\n",
    "    results_dict[job_name] = result['y_pred_proba']\n",
    "    all_metrics.extend(result['metrics'])\n",
    "    \n",
    "    log.append(f\"\\n{job_name}:\")\n",
    "    for msg in result['log']:\n",
    "        log.append(f\"  {msg}\")\n",
    "    \n",
    "    # Save model if configured\n",
    "    if config['output']['save_models']:\n",
    "        result['trainer'].save_model(f\"{run_folder}/models/{job_name}.pkl\")\n",
    "        log.append(f\"  Model saved\")\n",
    "\n",
    "# Create metrics DataFrame\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "print(f\"ðŸ“Š Results collected:\")\n",
    "print(f\"  Total models trained: {len(results)}\")\n",
    "print(f\"  Metrics computed: {len(all_metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5232a5",
   "metadata": {},
   "source": [
    "## 8. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3db68585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Performance Metrics:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>imbalance_method</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.751835</td>\n",
       "      <td>0.676092</td>\n",
       "      <td>0.735356</td>\n",
       "      <td>0.784438</td>\n",
       "      <td>8.618762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.746592</td>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.725458</td>\n",
       "      <td>0.775812</td>\n",
       "      <td>3.667660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.746592</td>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.725458</td>\n",
       "      <td>0.775812</td>\n",
       "      <td>3.161643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.748777</td>\n",
       "      <td>0.667082</td>\n",
       "      <td>0.729481</td>\n",
       "      <td>0.766780</td>\n",
       "      <td>17.118999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.759088</td>\n",
       "      <td>0.684406</td>\n",
       "      <td>0.742493</td>\n",
       "      <td>0.750566</td>\n",
       "      <td>5.438981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.730172</td>\n",
       "      <td>0.738521</td>\n",
       "      <td>6.630630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>svm</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.675927</td>\n",
       "      <td>0.733432</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>113.345848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>svm</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.675927</td>\n",
       "      <td>0.733432</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>106.957448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>svm</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.757690</td>\n",
       "      <td>0.696783</td>\n",
       "      <td>0.748202</td>\n",
       "      <td>0.753127</td>\n",
       "      <td>140.260691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>svm</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.753757</td>\n",
       "      <td>0.687676</td>\n",
       "      <td>0.742032</td>\n",
       "      <td>0.748594</td>\n",
       "      <td>156.190998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>svm</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.743272</td>\n",
       "      <td>0.665944</td>\n",
       "      <td>0.726755</td>\n",
       "      <td>0.742559</td>\n",
       "      <td>161.065841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>svm</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.744058</td>\n",
       "      <td>0.673194</td>\n",
       "      <td>0.730774</td>\n",
       "      <td>0.739858</td>\n",
       "      <td>167.986258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sgd</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.738815</td>\n",
       "      <td>0.687192</td>\n",
       "      <td>0.735273</td>\n",
       "      <td>0.735835</td>\n",
       "      <td>0.639528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sgd</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.724222</td>\n",
       "      <td>0.679668</td>\n",
       "      <td>0.724870</td>\n",
       "      <td>0.732074</td>\n",
       "      <td>0.618480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sgd</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.712775</td>\n",
       "      <td>0.657052</td>\n",
       "      <td>0.709357</td>\n",
       "      <td>0.726606</td>\n",
       "      <td>0.589381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sgd</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.708581</td>\n",
       "      <td>0.661062</td>\n",
       "      <td>0.709080</td>\n",
       "      <td>0.708653</td>\n",
       "      <td>0.785636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sgd</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720902</td>\n",
       "      <td>0.638959</td>\n",
       "      <td>0.704038</td>\n",
       "      <td>0.685434</td>\n",
       "      <td>0.520760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sgd</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720902</td>\n",
       "      <td>0.638959</td>\n",
       "      <td>0.704038</td>\n",
       "      <td>0.685434</td>\n",
       "      <td>0.508952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.754893</td>\n",
       "      <td>0.623593</td>\n",
       "      <td>0.707707</td>\n",
       "      <td>0.822096</td>\n",
       "      <td>120.416423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.648122</td>\n",
       "      <td>0.724720</td>\n",
       "      <td>0.820988</td>\n",
       "      <td>80.211845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.648122</td>\n",
       "      <td>0.724720</td>\n",
       "      <td>0.820988</td>\n",
       "      <td>80.035879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.761447</td>\n",
       "      <td>0.641257</td>\n",
       "      <td>0.719823</td>\n",
       "      <td>0.820761</td>\n",
       "      <td>102.324587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.750350</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.703248</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>117.023396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.749825</td>\n",
       "      <td>0.617022</td>\n",
       "      <td>0.702352</td>\n",
       "      <td>0.810406</td>\n",
       "      <td>151.882180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.733922</td>\n",
       "      <td>0.674578</td>\n",
       "      <td>0.727158</td>\n",
       "      <td>0.744721</td>\n",
       "      <td>0.150502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.733485</td>\n",
       "      <td>0.686309</td>\n",
       "      <td>0.732337</td>\n",
       "      <td>0.736674</td>\n",
       "      <td>0.136104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.721513</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>0.702204</td>\n",
       "      <td>0.730993</td>\n",
       "      <td>0.155569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.721513</td>\n",
       "      <td>0.634940</td>\n",
       "      <td>0.702204</td>\n",
       "      <td>0.730993</td>\n",
       "      <td>0.149616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.712251</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>0.711468</td>\n",
       "      <td>0.728807</td>\n",
       "      <td>0.147472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.708494</td>\n",
       "      <td>0.649167</td>\n",
       "      <td>0.703753</td>\n",
       "      <td>0.718289</td>\n",
       "      <td>0.150803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.765554</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>0.756684</td>\n",
       "      <td>0.810534</td>\n",
       "      <td>6.183877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.708819</td>\n",
       "      <td>0.760536</td>\n",
       "      <td>0.788165</td>\n",
       "      <td>19.208517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.777787</td>\n",
       "      <td>0.704916</td>\n",
       "      <td>0.760399</td>\n",
       "      <td>0.786338</td>\n",
       "      <td>16.032954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.777787</td>\n",
       "      <td>0.704916</td>\n",
       "      <td>0.760399</td>\n",
       "      <td>0.786338</td>\n",
       "      <td>19.790428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.764593</td>\n",
       "      <td>0.702025</td>\n",
       "      <td>0.753688</td>\n",
       "      <td>0.782467</td>\n",
       "      <td>11.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.760136</td>\n",
       "      <td>0.677113</td>\n",
       "      <td>0.739062</td>\n",
       "      <td>0.763603</td>\n",
       "      <td>8.248932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>knn</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.701066</td>\n",
       "      <td>0.619167</td>\n",
       "      <td>0.685989</td>\n",
       "      <td>0.640577</td>\n",
       "      <td>0.071223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>knn</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.683328</td>\n",
       "      <td>0.603223</td>\n",
       "      <td>0.670678</td>\n",
       "      <td>0.634883</td>\n",
       "      <td>0.064469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>knn</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693114</td>\n",
       "      <td>0.607369</td>\n",
       "      <td>0.676792</td>\n",
       "      <td>0.632330</td>\n",
       "      <td>0.067721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>knn</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693114</td>\n",
       "      <td>0.607369</td>\n",
       "      <td>0.676792</td>\n",
       "      <td>0.632330</td>\n",
       "      <td>0.078987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>knn</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.677211</td>\n",
       "      <td>0.600528</td>\n",
       "      <td>0.666750</td>\n",
       "      <td>0.630665</td>\n",
       "      <td>0.073899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>knn</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.676686</td>\n",
       "      <td>0.599879</td>\n",
       "      <td>0.666209</td>\n",
       "      <td>0.622494</td>\n",
       "      <td>0.065370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778224</td>\n",
       "      <td>0.727284</td>\n",
       "      <td>0.771880</td>\n",
       "      <td>0.792002</td>\n",
       "      <td>34.130745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.776652</td>\n",
       "      <td>0.709568</td>\n",
       "      <td>0.762381</td>\n",
       "      <td>0.789239</td>\n",
       "      <td>18.641140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.776652</td>\n",
       "      <td>0.709568</td>\n",
       "      <td>0.762381</td>\n",
       "      <td>0.789239</td>\n",
       "      <td>24.129035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.768700</td>\n",
       "      <td>0.726015</td>\n",
       "      <td>0.766933</td>\n",
       "      <td>0.778988</td>\n",
       "      <td>26.832376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.771583</td>\n",
       "      <td>0.731578</td>\n",
       "      <td>0.770787</td>\n",
       "      <td>0.770465</td>\n",
       "      <td>38.465057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.755680</td>\n",
       "      <td>0.703733</td>\n",
       "      <td>0.750672</td>\n",
       "      <td>0.766306</td>\n",
       "      <td>44.342597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.746942</td>\n",
       "      <td>0.604233</td>\n",
       "      <td>0.694153</td>\n",
       "      <td>0.817222</td>\n",
       "      <td>16.385327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.742310</td>\n",
       "      <td>0.608346</td>\n",
       "      <td>0.695014</td>\n",
       "      <td>0.809044</td>\n",
       "      <td>17.976743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.745281</td>\n",
       "      <td>0.608832</td>\n",
       "      <td>0.696245</td>\n",
       "      <td>0.806663</td>\n",
       "      <td>14.536323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.745281</td>\n",
       "      <td>0.608832</td>\n",
       "      <td>0.696245</td>\n",
       "      <td>0.806663</td>\n",
       "      <td>14.022860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.742136</td>\n",
       "      <td>0.606611</td>\n",
       "      <td>0.693975</td>\n",
       "      <td>0.801311</td>\n",
       "      <td>15.809726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>extra_trees</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.739514</td>\n",
       "      <td>0.600102</td>\n",
       "      <td>0.689440</td>\n",
       "      <td>0.801042</td>\n",
       "      <td>8.252562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.712164</td>\n",
       "      <td>0.635956</td>\n",
       "      <td>0.698977</td>\n",
       "      <td>0.629113</td>\n",
       "      <td>0.264766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.687260</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.680833</td>\n",
       "      <td>0.617142</td>\n",
       "      <td>0.225343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.687260</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.680833</td>\n",
       "      <td>0.617142</td>\n",
       "      <td>0.212930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.686473</td>\n",
       "      <td>0.616792</td>\n",
       "      <td>0.678620</td>\n",
       "      <td>0.612867</td>\n",
       "      <td>0.244581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.654404</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.652758</td>\n",
       "      <td>0.592071</td>\n",
       "      <td>0.280292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.623646</td>\n",
       "      <td>0.534634</td>\n",
       "      <td>0.611641</td>\n",
       "      <td>0.534719</td>\n",
       "      <td>0.402031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>kmeans_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.751835</td>\n",
       "      <td>0.711654</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.772058</td>\n",
       "      <td>20.560016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.756029</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>0.749130</td>\n",
       "      <td>0.758420</td>\n",
       "      <td>16.084281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.756029</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>0.749130</td>\n",
       "      <td>0.758420</td>\n",
       "      <td>16.211633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702115</td>\n",
       "      <td>0.664120</td>\n",
       "      <td>0.706863</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>20.328732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>svmsmote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.723960</td>\n",
       "      <td>0.687245</td>\n",
       "      <td>0.727790</td>\n",
       "      <td>0.746762</td>\n",
       "      <td>23.114925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>borderline_smote</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.722562</td>\n",
       "      <td>0.674666</td>\n",
       "      <td>0.721897</td>\n",
       "      <td>0.722056</td>\n",
       "      <td>24.415653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  imbalance_method  threshold  accuracy  macro_f1  \\\n",
       "21              xgboost          svmsmote        0.5  0.751835  0.676092   \n",
       "18              xgboost              none        0.5  0.746592  0.661014   \n",
       "20              xgboost            adasyn        0.5  0.746592  0.661014   \n",
       "23              xgboost  borderline_smote        0.5  0.748777  0.667082   \n",
       "22              xgboost      kmeans_smote        0.5  0.759088  0.684406   \n",
       "19              xgboost             smote        0.5  0.747204  0.669572   \n",
       "42                  svm              none        0.5  0.747204  0.675927   \n",
       "44                  svm            adasyn        0.5  0.747204  0.675927   \n",
       "46                  svm      kmeans_smote        0.5  0.757690  0.696783   \n",
       "43                  svm             smote        0.5  0.753757  0.687676   \n",
       "47                  svm  borderline_smote        0.5  0.743272  0.665944   \n",
       "45                  svm          svmsmote        0.5  0.744058  0.673194   \n",
       "52                  sgd      kmeans_smote        0.5  0.738815  0.687192   \n",
       "49                  sgd             smote        0.5  0.724222  0.679668   \n",
       "53                  sgd  borderline_smote        0.5  0.712775  0.657052   \n",
       "51                  sgd          svmsmote        0.5  0.708581  0.661062   \n",
       "48                  sgd              none        0.5  0.720902  0.638959   \n",
       "50                  sgd            adasyn        0.5  0.720902  0.638959   \n",
       "10        random_forest      kmeans_smote        0.5  0.754893  0.623593   \n",
       "6         random_forest              none        0.5  0.764593  0.648122   \n",
       "8         random_forest            adasyn        0.5  0.764593  0.648122   \n",
       "7         random_forest             smote        0.5  0.761447  0.641257   \n",
       "9         random_forest          svmsmote        0.5  0.750350  0.618305   \n",
       "11        random_forest  borderline_smote        0.5  0.749825  0.617022   \n",
       "4   logistic_regression      kmeans_smote        0.5  0.733922  0.674578   \n",
       "1   logistic_regression             smote        0.5  0.733485  0.686309   \n",
       "0   logistic_regression              none        0.5  0.721513  0.634940   \n",
       "2   logistic_regression            adasyn        0.5  0.721513  0.634940   \n",
       "3   logistic_regression          svmsmote        0.5  0.712251  0.662362   \n",
       "5   logistic_regression  borderline_smote        0.5  0.708494  0.649167   \n",
       "27             lightgbm          svmsmote        0.5  0.765554  0.707254   \n",
       "25             lightgbm             smote        0.5  0.772981  0.708819   \n",
       "26             lightgbm            adasyn        0.5  0.777787  0.704916   \n",
       "24             lightgbm              none        0.5  0.777787  0.704916   \n",
       "29             lightgbm  borderline_smote        0.5  0.764593  0.702025   \n",
       "28             lightgbm      kmeans_smote        0.5  0.760136  0.677113   \n",
       "40                  knn      kmeans_smote        0.5  0.701066  0.619167   \n",
       "37                  knn             smote        0.5  0.683328  0.603223   \n",
       "36                  knn              none        0.5  0.693114  0.607369   \n",
       "38                  knn            adasyn        0.5  0.693114  0.607369   \n",
       "39                  knn          svmsmote        0.5  0.677211  0.600528   \n",
       "41                  knn  borderline_smote        0.5  0.676686  0.599879   \n",
       "16    gradient_boosting      kmeans_smote        0.5  0.778224  0.727284   \n",
       "12    gradient_boosting              none        0.5  0.776652  0.709568   \n",
       "14    gradient_boosting            adasyn        0.5  0.776652  0.709568   \n",
       "13    gradient_boosting             smote        0.5  0.768700  0.726015   \n",
       "15    gradient_boosting          svmsmote        0.5  0.771583  0.731578   \n",
       "17    gradient_boosting  borderline_smote        0.5  0.755680  0.703733   \n",
       "64          extra_trees      kmeans_smote        0.5  0.746942  0.604233   \n",
       "61          extra_trees             smote        0.5  0.742310  0.608346   \n",
       "60          extra_trees              none        0.5  0.745281  0.608832   \n",
       "62          extra_trees            adasyn        0.5  0.745281  0.608832   \n",
       "65          extra_trees  borderline_smote        0.5  0.742136  0.606611   \n",
       "63          extra_trees          svmsmote        0.5  0.739514  0.600102   \n",
       "34        decision_tree      kmeans_smote        0.5  0.712164  0.635956   \n",
       "32        decision_tree            adasyn        0.5  0.687260  0.620731   \n",
       "30        decision_tree              none        0.5  0.687260  0.620731   \n",
       "33        decision_tree          svmsmote        0.5  0.686473  0.616792   \n",
       "31        decision_tree             smote        0.5  0.654404  0.592872   \n",
       "35        decision_tree  borderline_smote        0.5  0.623646  0.534634   \n",
       "58             adaboost      kmeans_smote        0.5  0.751835  0.711654   \n",
       "54             adaboost              none        0.5  0.756029  0.700158   \n",
       "56             adaboost            adasyn        0.5  0.756029  0.700158   \n",
       "55             adaboost             smote        0.5  0.702115  0.664120   \n",
       "57             adaboost          svmsmote        0.5  0.723960  0.687245   \n",
       "59             adaboost  borderline_smote        0.5  0.722562  0.674666   \n",
       "\n",
       "    weighted_f1       auc  train_time  \n",
       "21     0.735356  0.784438    8.618762  \n",
       "18     0.725458  0.775812    3.667660  \n",
       "20     0.725458  0.775812    3.161643  \n",
       "23     0.729481  0.766780   17.118999  \n",
       "22     0.742493  0.750566    5.438981  \n",
       "19     0.730172  0.738521    6.630630  \n",
       "42     0.733432  0.756447  113.345848  \n",
       "44     0.733432  0.756447  106.957448  \n",
       "46     0.748202  0.753127  140.260691  \n",
       "43     0.742032  0.748594  156.190998  \n",
       "47     0.726755  0.742559  161.065841  \n",
       "45     0.730774  0.739858  167.986258  \n",
       "52     0.735273  0.735835    0.639528  \n",
       "49     0.724870  0.732074    0.618480  \n",
       "53     0.709357  0.726606    0.589381  \n",
       "51     0.709080  0.708653    0.785636  \n",
       "48     0.704038  0.685434    0.520760  \n",
       "50     0.704038  0.685434    0.508952  \n",
       "10     0.707707  0.822096  120.416423  \n",
       "6      0.724720  0.820988   80.211845  \n",
       "8      0.724720  0.820988   80.035879  \n",
       "7      0.719823  0.820761  102.324587  \n",
       "9      0.703248  0.810526  117.023396  \n",
       "11     0.702352  0.810406  151.882180  \n",
       "4      0.727158  0.744721    0.150502  \n",
       "1      0.732337  0.736674    0.136104  \n",
       "0      0.702204  0.730993    0.155569  \n",
       "2      0.702204  0.730993    0.149616  \n",
       "3      0.711468  0.728807    0.147472  \n",
       "5      0.703753  0.718289    0.150803  \n",
       "27     0.756684  0.810534    6.183877  \n",
       "25     0.760536  0.788165   19.208517  \n",
       "26     0.760399  0.786338   16.032954  \n",
       "24     0.760399  0.786338   19.790428  \n",
       "29     0.753688  0.782467   11.110791  \n",
       "28     0.739062  0.763603    8.248932  \n",
       "40     0.685989  0.640577    0.071223  \n",
       "37     0.670678  0.634883    0.064469  \n",
       "36     0.676792  0.632330    0.067721  \n",
       "38     0.676792  0.632330    0.078987  \n",
       "39     0.666750  0.630665    0.073899  \n",
       "41     0.666209  0.622494    0.065370  \n",
       "16     0.771880  0.792002   34.130745  \n",
       "12     0.762381  0.789239   18.641140  \n",
       "14     0.762381  0.789239   24.129035  \n",
       "13     0.766933  0.778988   26.832376  \n",
       "15     0.770787  0.770465   38.465057  \n",
       "17     0.750672  0.766306   44.342597  \n",
       "64     0.694153  0.817222   16.385327  \n",
       "61     0.695014  0.809044   17.976743  \n",
       "60     0.696245  0.806663   14.536323  \n",
       "62     0.696245  0.806663   14.022860  \n",
       "65     0.693975  0.801311   15.809726  \n",
       "63     0.689440  0.801042    8.252562  \n",
       "34     0.698977  0.629113    0.264766  \n",
       "32     0.680833  0.617142    0.225343  \n",
       "30     0.680833  0.617142    0.212930  \n",
       "33     0.678620  0.612867    0.244581  \n",
       "31     0.652758  0.592071    0.280292  \n",
       "35     0.611641  0.534719    0.402031  \n",
       "58     0.752381  0.772058   20.560016  \n",
       "54     0.749130  0.758420   16.084281  \n",
       "56     0.749130  0.758420   16.211633  \n",
       "55     0.706863  0.747419   20.328732  \n",
       "57     0.727790  0.746762   23.114925  \n",
       "59     0.721897  0.722056   24.415653  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display metrics table\n",
    "print(\"\\nðŸ“‹ Performance Metrics:\\n\")\n",
    "\n",
    "if 'threshold' in metrics_df.columns:\n",
    "    display_df = metrics_df.copy()\n",
    "else:\n",
    "    display_df = metrics_df.copy()\n",
    "\n",
    "display_df = display_df.sort_values('auc', ascending=False)\n",
    "display(display_df[['model', 'imbalance_method', 'threshold', 'accuracy', 'macro_f1', 'weighted_f1', 'auc', 'train_time']].sort_values(by=[\"model\", \"auc\"], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbb92028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print the final df\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bed1c",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95bac6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = Visualizer()\n",
    "\n",
    "# if config['output']['save_plots']:\n",
    "#     if dataset_info['task_type'] == \"binary\":\n",
    "#         # Binary classification plots\n",
    "#         visualizer.plot_roc_curves(results_dict, y_test, f\"{run_folder}/plots/roc_curves.png\")\n",
    "#         visualizer.plot_confusion_matrices(results_dict, y_test, 0.5, f\"{run_folder}/plots/confusion_matrices.png\")\n",
    "#     else:\n",
    "#         # Multi-class plots\n",
    "#         visualizer.plot_multiclass_roc(results_dict, y_test, f\"{run_folder}/plots/roc_curves_multiclass.png\")\n",
    "    \n",
    "#     # Metrics comparison (works for both binary and multiclass)\n",
    "#     visualizer.plot_metrics_comparison(metrics_df, f\"{run_folder}/plots/metrics_comparison.png\")\n",
    "    \n",
    "#     print(f\"\\nðŸ“Š Plots saved to {run_folder}/plots/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec362f4",
   "metadata": {},
   "source": [
    "## 10. Save Results and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38f55406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… Run Complete!\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Results saved to: results/run_20260208_223713\n",
      "\n",
      "ðŸ† Best Model:\n",
      "  - Model: random_forest\n",
      "  - Imbalance method: kmeans_smote\n",
      "  - AUC: 0.8221\n",
      "  - Accuracy: 0.7549\n",
      "\n",
      "ðŸ“„ Files created:\n",
      "  - summary.json (quick overview)\n",
      "  - metrics.csv (detailed metrics)\n",
      "  - training.log (execution logs)\n",
      "  - plots/ (visualizations)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save all results\n",
    "save_summary(run_folder, config, metrics_df, dataset_info)\n",
    "save_metrics(run_folder, metrics_df)\n",
    "save_training_log(run_folder, log)\n",
    "\n",
    "# Print summary\n",
    "best_idx = metrics_df['auc'].idxmax()\n",
    "best_model = metrics_df.loc[best_idx, 'model']\n",
    "best_method = metrics_df.loc[best_idx, 'imbalance_method']\n",
    "best_auc = metrics_df.loc[best_idx, 'auc']\n",
    "best_acc = metrics_df.loc[best_idx, 'accuracy']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ… Run Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nðŸ“ Results saved to: {run_folder}\")\n",
    "print(f\"\\nðŸ† Best Model:\")\n",
    "print(f\"  - Model: {best_model}\")\n",
    "print(f\"  - Imbalance method: {best_method}\")\n",
    "print(f\"  - AUC: {best_auc:.4f}\")\n",
    "print(f\"  - Accuracy: {best_acc:.4f}\")\n",
    "print(f\"\\nðŸ“„ Files created:\")\n",
    "print(f\"  - summary.json (quick overview)\")\n",
    "print(f\"  - metrics.csv (detailed metrics)\")\n",
    "print(f\"  - training.log (execution logs)\")\n",
    "if config['output']['save_plots']:\n",
    "    print(f\"  - plots/ (visualizations)\")\n",
    "if config['output']['save_models']:\n",
    "    print(f\"  - models/ (trained models)\")\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f0e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
