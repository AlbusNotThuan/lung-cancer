{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eed65ae",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline (Hoang's Method)\n",
    "\n",
    "This notebook processes lung cancer data following Hoang's approach:\n",
    "1. Load and encode data\n",
    "2. Split by hospital group\n",
    "3. Apply MICE imputation (avoiding data leakage)\n",
    "4. Export processed datasets as CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3df88e",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ebcbd",
   "metadata": {},
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"data_ML_full.xlsx\", header=0)\n",
    "\n",
    "print(\"ğŸ“‹ Dataset shape:\", df.shape)\n",
    "print(\"\\nğŸ” First few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7922ae",
   "metadata": {},
   "source": [
    "## Step 3: Encode Patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47419582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple numeric IDs\n",
    "le_id = LabelEncoder()\n",
    "df['ID_simple'] = le_id.fit_transform(df['ID_NO'].astype(str))\n",
    "\n",
    "# Save ID mapping table for reference\n",
    "id_mapping = pd.DataFrame({\n",
    "    'Original_ID': le_id.classes_,\n",
    "    'Simple_ID': range(len(le_id.classes_))\n",
    "})\n",
    "id_mapping.to_csv('ID_Mapping_Table.csv', index=False)\n",
    "\n",
    "print(\"âœ… ID encoding completed\")\n",
    "print(f\"âœ… ID mapping saved to 'ID_Mapping_Table.csv'\")\n",
    "print(f\"\\nğŸ” Sample ID mapping:\")\n",
    "df[['ID_NO', 'ID_simple']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874096a",
   "metadata": {},
   "source": [
    "## Step 4: Label Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba36104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non-numeric columns\n",
    "non_num_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Exclude ID_NO, hosp_grp, and dead from encoding\n",
    "exclude_cols = [\"ID_NO\", \"hosp_grp\", \"dead\"]\n",
    "encode_cols = [c for c in non_num_cols if c not in exclude_cols]\n",
    "encode_cols = list(set(encode_cols))\n",
    "\n",
    "print(f\"ğŸ§© Non-numeric columns: {non_num_cols}\")\n",
    "print(f\"\\nâœ… Columns to encode: {encode_cols}\")\n",
    "\n",
    "# Apply LabelEncoder to each column\n",
    "df_encoded = df.copy()\n",
    "for col in encode_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    print(f\"ğŸ”¢ Encoded '{col}' with {len(le.classes_)} unique values\")\n",
    "\n",
    "# Convert boolean columns to float\n",
    "bool_cols = df_encoded.select_dtypes(include=['bool']).columns\n",
    "if len(bool_cols) > 0:\n",
    "    print(f\"\\nğŸ§© Converting {len(bool_cols)} boolean columns to float\")\n",
    "    df_encoded[bool_cols] = df_encoded[bool_cols].astype(float)\n",
    "\n",
    "print(f\"\\nâœ… Encoded dataframe shape: {df_encoded.shape}\")\n",
    "print(f\"ğŸ“Š Data types after encoding:\")\n",
    "print(df_encoded.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2b6e0",
   "metadata": {},
   "source": [
    "## Step 5: Identify Gene/Special Columns (to exclude from imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeddd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify gene/mutation columns using pattern matching\n",
    "keywords = [\"pdl1\", \"ros1\", \"alk\", \"egfr\", \"exon21_all\", \"exon20_all\", \"exon19_all\", \"exon18_all\", \"ct\", \"cstage\"]\n",
    "pattern = r'(^|_)(' + '|'.join(keywords) + r')($|_)'\n",
    "\n",
    "special_cols = [c for c in df_encoded.columns if re.search(pattern, c.lower())]\n",
    "special_cols = [c for c in special_cols if c.lower() != \"first_egfr\"]\n",
    "\n",
    "print(\"ğŸ§¬ Gene/Cancer stage related columns (excluded from imputation):\")\n",
    "print(special_cols)\n",
    "print(f\"\\nâœ… Total special columns: {len(special_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9655d2",
   "metadata": {},
   "source": [
    "## Step 6: Split Data by Hospital Group (BEFORE Imputation)\n",
    "\n",
    "**Note:** Train = Hospitals w+t (all data), Test = Hospital s (external validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¥ Splitting data by Hospital Group...\")\n",
    "\n",
    "# Training Set (Hospitals \"w\" and \"t\" - ALL data)\n",
    "df_train = df_encoded[df_encoded[\"hosp_grp\"].isin([\"w\", \"t\"])].copy()\n",
    "\n",
    "# Test Set (Hospital \"s\" - external validation)\n",
    "df_test = df_encoded[df_encoded[\"hosp_grp\"] == \"s\"].copy()\n",
    "\n",
    "# Separate features and target\n",
    "X_train = df_train.drop(columns=[\"dead\", \"follow_up\", \"hosp_grp\", \"ID_NO\"], errors=\"ignore\")\n",
    "y_train = df_train[\"dead\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"dead\", \"follow_up\", \"hosp_grp\", \"ID_NO\"], errors=\"ignore\")\n",
    "y_test = df_test[\"dead\"]\n",
    "\n",
    "print(f\"âœ… Split Summary:\")\n",
    "print(f\"   - Train set (Hospitals w+t): {X_train.shape}\")\n",
    "print(f\"   - Test set (Hospital s): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b35890",
   "metadata": {},
   "source": [
    "## Step 7: Apply MICE Imputation (Avoiding Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb276831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for imputation (excluding gene/special columns)\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "cols_to_impute = [c for c in num_cols if c not in special_cols]\n",
    "\n",
    "print(f\"\\nâœ… Numerical columns selected for MICE: {len(cols_to_impute)}\")\n",
    "print(f\"ğŸ§¬ Excluded gene/stage columns: {len(special_cols)}\")\n",
    "\n",
    "# Initialize MICE Imputer\n",
    "imputer = IterativeImputer(random_state=42, max_iter=1000, sample_posterior=True)\n",
    "\n",
    "# Helper function to apply MICE imputation\n",
    "def apply_mice(df_input, imputer_model, fit=False):\n",
    "    \"\"\"Apply MICE imputation to selected columns only\"\"\"\n",
    "    df_out = df_input.copy()\n",
    "    data_to_impute = df_out[cols_to_impute]\n",
    "    \n",
    "    if fit:\n",
    "        # FIT on training data - learns relationships\n",
    "        imputed_data = imputer_model.fit_transform(data_to_impute)\n",
    "    else:\n",
    "        # TRANSFORM on validation/test - uses learned relationships\n",
    "        imputed_data = imputer_model.transform(data_to_impute)\n",
    "    \n",
    "    # Assign imputed data back to dataframe\n",
    "    df_out[cols_to_impute] = imputed_data\n",
    "    return df_out\n",
    "\n",
    "print(\"\\nğŸ”„ Running MICE Imputation...\")\n",
    "\n",
    "# 1. Fit & Transform on TRAIN (hospitals w+t)\n",
    "X_train_imputed = apply_mice(X_train, imputer, fit=True)\n",
    "print(\"   - Train set imputed âœ…\")\n",
    "\n",
    "# 2. Transform on TEST (hospital s) - no fit, avoids leakage\n",
    "X_test_imputed = apply_mice(X_test, imputer, fit=False)\n",
    "print(\"   - Test set imputed âœ…\")\n",
    "\n",
    "# Verify no data leakage - check if gene columns unchanged\n",
    "sample_gene = special_cols[0] if len(special_cols) > 0 else None\n",
    "if sample_gene and sample_gene in X_test.columns:\n",
    "    before = X_test[sample_gene].fillna(-999)\n",
    "    after = X_test_imputed[sample_gene].fillna(-999)\n",
    "    if (before == after).all():\n",
    "        print(f\"\\nâœ… Safety Check: Gene column '{sample_gene}' was NOT modified by MICE\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ WARNING: Gene column '{sample_gene}' WAS modified!\")\n",
    "\n",
    "# Check remaining missing values\n",
    "missing_remaining = X_train_imputed[cols_to_impute].isna().mean().sum()\n",
    "print(f\"\\nğŸ“‰ Missing values remaining in Train (imputed cols): {missing_remaining:.4f}\")\n",
    "print(\"\\nğŸ‰ Imputation Complete: No data leakage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b784eaf",
   "metadata": {},
   "source": [
    "## Step 8: Final Cleanup (Fill remaining NaN with -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any remaining NaN values with -1\n",
    "X_train_final = X_train_imputed.fillna(-1)\n",
    "X_test_final = X_test_imputed.fillna(-1)\n",
    "\n",
    "print(\"âœ… Filled remaining NaN values with -1\")\n",
    "print(f\"\\nğŸ“Š Final dataset shapes:\")\n",
    "print(f\"   - Train: {X_train_final.shape}\")\n",
    "print(f\"   - Test: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c64c18",
   "metadata": {},
   "source": [
    "## Step 9: Export Processed Data to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features with target labels for export\n",
    "train_data = X_train_final.copy()\n",
    "train_data['dead'] = y_train.values\n",
    "\n",
    "test_data = X_test_final.copy()\n",
    "test_data['dead'] = y_test.values\n",
    "\n",
    "# Export to CSV\n",
    "train_data.to_csv('lung_train.csv', index=False)\n",
    "test_data.to_csv('lung_test.csv', index=False)\n",
    "\n",
    "print(\"âœ… Data exported successfully!\")\n",
    "print(f\"\\nğŸ“ Files created:\")\n",
    "print(f\"   - lung_train.csv ({train_data.shape[0]} rows, {train_data.shape[1]} columns)\")\n",
    "print(f\"   - lung_test.csv ({test_data.shape[0]} rows, {test_data.shape[1]} columns)\")\n",
    "print(f\"   - ID_Mapping_Table.csv (for ID reference)\")\n",
    "\n",
    "print(\"\\nğŸ¯ Processing Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b05d6a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook processed the lung cancer dataset following Hoang's methodology:\n",
    "\n",
    "**Key Steps:**\n",
    "1. âœ… Loaded raw data from Excel\n",
    "2. âœ… Encoded patient IDs (saved mapping table)\n",
    "3. âœ… Label-encoded all categorical variables\n",
    "4. âœ… Identified gene/mutation columns to preserve\n",
    "5. âœ… Split data by hospital group (w+t for train, s for test)\n",
    "6. âœ… Applied MICE imputation WITHOUT data leakage\n",
    "7. âœ… Filled remaining NaN with -1\n",
    "8. âœ… Exported 2 CSV files\n",
    "\n",
    "**Output Files:**\n",
    "- `lung_train.csv` - Training set (Hospitals w+t - ALL data)\n",
    "- `lung_test.csv` - Test set (Hospital s - external validation)\n",
    "- `ID_Mapping_Table.csv` - ID reference table\n",
    "\n",
    "**Data Integrity:**\n",
    "- âœ… No data leakage (imputer fitted only on training data from w+t)\n",
    "- âœ… Gene/mutation columns preserved\n",
    "- âœ… External test set (hospital s) remains independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ed67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
